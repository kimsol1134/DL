{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, concatenate, GlobalAveragePooling2D, AveragePooling2D, Flatten, Dropout, Input\n",
    "from keras.datasets import cifar10\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_data(img_rows, img_cols):\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = x_train[0:1000, :, :]\n",
    "    y_train = y_train[:1000]\n",
    "\n",
    "    x_test = x_test[:500,:,:,:]\n",
    "    y_test = y_test[:500]\n",
    "\n",
    "    x_train = np.array([cv2.resize(img, (img_rows, img_cols)) for img in x_train])\n",
    "    x_test = np.array([cv2.resize(img, (img_rows, img_cols)) for img in x_test])\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test = load_cifar10_data(224,224)\n",
    "img_input = Input(shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj, name=None, kernel_init='glorot_uniform', bias_init='zero'):\n",
    "    conv_1x1 = Conv2D(filters_1x1, (1,1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    conv_3x3_reduce = Conv2D(filters_3x3_reduce,(1,1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3,3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_3x3_reduce)\n",
    "    conv_5x5_reduce = Conv2D(filters_5x5_reduce, (1,1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    conv_5x5 = Conv2D(filters_5x5, (5,5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    max_pool = MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
    "    pool_proj = Conv2D(filters_pool_proj, (1,1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(max_pool)\n",
    "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay(epoch, steps=100): # epoch 마다 lerning rate 감소\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.96\n",
    "    epoch_drop = 8\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 +epoch)/ epoch_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_init = keras.initializers.glorot_uniform()\n",
    "bias_init = keras.initializers.Constant(value=0.2)\n",
    "input_layer = Input(shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 부분\n",
    "x = Conv2D(64, (7,7), padding='same', strides=(2,2), activation='relu', \n",
    "           name='conv_1_7x7-2', kernel_initializer = kernel_init, bias_initializer=bias_init)(input_layer)\n",
    "x = MaxPool2D((3,3), strides=(2,2), name='max_pool_1_3x3-2', padding='same')(x)\n",
    "\n",
    "x = Conv2D(192, (3,3), padding='same', strides=(1,1), activation='relu',\n",
    "           name='conv_2_3x3-1', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "x = MaxPool2D((3,3), strides=(2,2), name='max_pool_2_3x3-2', padding='same')(x)\n",
    "\n",
    "# 중간 부분\n",
    "x = inception_module(x, 64, 96, 128, 16, 32, 32, name='inception_3a', kernel_init=kernel_init,bias_init=bias_init)\n",
    "x = inception_module(x, 128, 128, 192, 32, 96, 64, name='inception_3b', kernel_init=kernel_init, bias_init=bias_init)\n",
    "x = MaxPool2D((3,3), strides=(2,2), name='max_pool_3_3x3-2')(x)\n",
    "x = inception_module(x, 192, 96, 208, 16, 48, 64, name='inception_4a')\n",
    "\n",
    "#중간 부분의 첫 번쨰 보조 분류기\n",
    "x1 = AveragePooling2D((5,5), strides=3, name='avg_pool_aux_1')(x)\n",
    "x1 = Conv2D(128, (1,1), padding='same', activation='relu', name='conv_aux_1')(x1)\n",
    "x1 = Flatten()(x1)\n",
    "x1 = Dense(1024, activation='relu', name='dense_aux_1')(x1)\n",
    "x1 = Dense(10, activation='softmax', name='aux_output_1')(x1)\n",
    "\n",
    "x = inception_module(x, 160, 112, 224, 24, 64, 64, name='inception_4b', kernel_init=kernel_init, bias_init=bias_init)\n",
    "x = inception_module(x, 128, 128, 256, 24, 64, 64, name='inception_4c', kernel_init=kernel_init, bias_init=bias_init)\n",
    "x = inception_module(x, 112, 144, 288, 32, 64, 64, name='inception_4d', kernel_init=kernel_init, bias_init=bias_init)\n",
    "\n",
    "# 중간 부분의 두 번쨰 보조 분류지\n",
    "x2 = AveragePooling2D((5, 5), strides=3, name='avg_pool_aux_2')(x)\n",
    "x2 = Conv2D(128, (1, 1), padding='same', activation='relu', name='conv_aux_2')(x2)\n",
    "x2 = Flatten()(x2)\n",
    "x2 = Dense(1024, activation='relu', name='dense_aux_2')(x2)\n",
    "x2 = Dense(10, activation='softmax', name='aux_output_2')(x2)\n",
    "\n",
    "x = inception_module(x, 256, 160, 320, 32, 128, 128, name='inception_4e', kernel_init=kernel_init, bias_init=bias_init)\n",
    "x = MaxPool2D((3,3), strides=(2,2), name='max_pool_4_3x3-2')(x)\n",
    "x = inception_module(x, 256, 160, 320, 32, 128, 128, name='inception_5a', kernel_init=kernel_init, bias_init=bias_init)\n",
    "x = inception_module(x, 384, 192, 384, 48, 128, 128, name='inception_5b', kernel_init=kernel_init, bias_init=bias_init)\n",
    "\n",
    "# 끝 부분\n",
    "x = GlobalAveragePooling2D(name='global_avg_pool_5_3x3-1')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(10, activation='softmax', name='output')(x)\n",
    "\n",
    "# 모델 저장\n",
    "model = Model(input_layer, [x ,x1, x2], name='GoogLeNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 1/3\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - aux_output_1_accuracy: 0.1068 - aux_output_1_loss: 0.6996 - aux_output_2_accuracy: 0.0929 - aux_output_2_loss: 0.7059 - loss: 3.9763 - output_accuracy: 0.1157 - output_loss: 2.5707 - val_aux_output_1_accuracy: 0.0980 - val_aux_output_1_loss: 0.6925 - val_aux_output_2_accuracy: 0.1080 - val_aux_output_2_loss: 0.6955 - val_loss: 3.7658 - val_output_accuracy: 0.1080 - val_output_loss: 2.3798 - learning_rate: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 2/3\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - aux_output_1_accuracy: 0.1284 - aux_output_1_loss: 0.6909 - aux_output_2_accuracy: 0.0934 - aux_output_2_loss: 0.6929 - loss: 3.7699 - output_accuracy: 0.0861 - output_loss: 2.3862 - val_aux_output_1_accuracy: 0.0820 - val_aux_output_1_loss: 0.6905 - val_aux_output_2_accuracy: 0.0820 - val_aux_output_2_loss: 0.6921 - val_loss: 3.7603 - val_output_accuracy: 0.1140 - val_output_loss: 2.3765 - learning_rate: 0.0100\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 3/3\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - aux_output_1_accuracy: 0.1082 - aux_output_1_loss: 0.6892 - aux_output_2_accuracy: 0.1139 - aux_output_2_loss: 0.6908 - loss: 3.7783 - output_accuracy: 0.0907 - output_loss: 2.3983 - val_aux_output_1_accuracy: 0.1320 - val_aux_output_1_loss: 0.6845 - val_aux_output_2_accuracy: 0.1260 - val_aux_output_2_loss: 0.6881 - val_loss: 3.6927 - val_output_accuracy: 0.1320 - val_output_loss: 2.3200 - learning_rate: 0.0100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30972df10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=False)\n",
    "lr_sc = LearningRateScheduler(decay, verbose=1)\n",
    "model.compile(loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'],\n",
    "              loss_weights=[1, 0.3, 0.3], optimizer=sgd, metrics=[['accuracy'], ['accuracy'], ['accuracy']])\n",
    "model.fit(x_train, [y_train, y_train, y_train], validation_data=(x_test, [y_test, y_test, y_test]), epochs=3, callbacks=[lr_sc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 522ms/step - aux_output_1_accuracy: 0.0000e+00 - aux_output_1_loss: 0.0000e+00 - aux_output_2_accuracy: 0.0000e+00 - aux_output_2_loss: 0.0000e+00 - loss: 2.3025 - output_accuracy: 0.1509 - output_loss: 2.3025\n",
      "테스트 정확도 : 2.3200290203094482\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print('테스트 정확도 :', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
