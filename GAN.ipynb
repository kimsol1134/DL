{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LeakyReLU, Reshape\n",
    "from keras.datasets import fashion_mnist\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (_,_) = fashion_mnist.load_data()\n",
    "x_train = x_train / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/multiplabel/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-09-30 13:49:58.592527: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-09-30 13:49:58.592547: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-09-30 13:49:58.592561: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-09-30 13:49:58.592576: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-30 13:49:58.592592: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/opt/anaconda3/envs/multiplabel/lib/python3.9/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "generator = Sequential()\n",
    "generator.add(Dense(512, input_shape =[100]))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(Dense(256))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(Dense(128))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(Dense(784))\n",
    "generator.add(Reshape([28,28,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "discriminator.add(Dense(1, input_shape=[28,28,1]))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(256))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dense(128))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dense(64))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = Sequential([generator,discriminator])\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "discriminator.trainable= False\n",
    "GAN.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 13:49:59.005931: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "/opt/anaconda3/envs/multiplabel/lib/python3.9/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (128, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x16ffb3040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x17a5b25e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "noise_shape = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(x_train.shape[0]//batch_size):\n",
    "        noise=np.random.normal(size=[batch_size, noise_shape])\n",
    "        gen_image = generator.predict_on_batch(noise)\n",
    "        train_dataset = x_train[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "        train_label=np.ones(shape=(batch_size,1))\n",
    "        discriminator.trainable = True\n",
    "        d_loss_real = discriminator.train_on_batch(train_dataset, train_label)\n",
    "\n",
    "        train_label = np.zeros(shape=(batch_size,1))\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_image,train_label)\n",
    "\n",
    "        noise=np.random.normal(size=[batch_size,noise_shape])\n",
    "        train_label=np.ones(shape=(batch_size,1))\n",
    "        discriminator.trainable = False\n",
    "        d_g_loss_batch = GAN.train_on_batch(noise, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(size=[10, noise_shape])\n",
    "\n",
    "gen_image = generator.predict(noise)\n",
    "plt.imshow(noise)\n",
    "\n",
    "fig,axe=plt.subplots(2,5)\n",
    "idx=0\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        axe[i,j].imshow(gen_image[idx].reshape(28,28), cmap='gray')\n",
    "        idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
